{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f97f638",
   "metadata": {},
   "source": [
    "# Tutorial on Training Classification models using BilbyStats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b42bcf1",
   "metadata": {},
   "source": [
    "In this is short tutorial we train, run and evaluate some basic transformer based models for classification. First we have an example on a small dataset that runs quickly. We then consider larger datasets below. The dataset we will use is originally from https://www.kaggle.com/datasets/ankurzing/sentiment-analysis-in-commodity-market-gold but is saved in bilbystats. It is a news dataset consisting of over 10000 news headlines regarding commodities. The headlines are in English but I have also translated them to Chinese so that I can illustrate analysis using Chinese Transformer based models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8931c81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dates</th>\n",
       "      <th>URL</th>\n",
       "      <th>News</th>\n",
       "      <th>Price Direction Up</th>\n",
       "      <th>Price Direction Constant</th>\n",
       "      <th>Price Direction Down</th>\n",
       "      <th>Asset Comparision</th>\n",
       "      <th>Past Information</th>\n",
       "      <th>Future Information</th>\n",
       "      <th>Price Sentiment</th>\n",
       "      <th>News_Chinese</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28-01-2016</td>\n",
       "      <td>http://www.marketwatch.com/story/april-gold-do...</td>\n",
       "      <td>april gold down 20 cents to settle at $1,116.1...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "      <td>四月黄金期货下跌20美分，收于每盎司1116.10美元。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13-09-2017</td>\n",
       "      <td>http://www.marketwatch.com/story/gold-prices-s...</td>\n",
       "      <td>gold suffers third straight daily decline</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "      <td>黄金遭遇连续第三天下跌</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26-07-2016</td>\n",
       "      <td>http://www.marketwatch.com/story/gold-futures-...</td>\n",
       "      <td>Gold futures edge up after two-session decline</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>positive</td>\n",
       "      <td>黄金期货在两日下跌后小幅上涨</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Dates                                                URL  \\\n",
       "0  28-01-2016  http://www.marketwatch.com/story/april-gold-do...   \n",
       "1  13-09-2017  http://www.marketwatch.com/story/gold-prices-s...   \n",
       "2  26-07-2016  http://www.marketwatch.com/story/gold-futures-...   \n",
       "\n",
       "                                                News  Price Direction Up  \\\n",
       "0  april gold down 20 cents to settle at $1,116.1...                   0   \n",
       "1          gold suffers third straight daily decline                   0   \n",
       "2     Gold futures edge up after two-session decline                   1   \n",
       "\n",
       "   Price Direction Constant  Price Direction Down  Asset Comparision  \\\n",
       "0                         0                     1                  0   \n",
       "1                         0                     1                  0   \n",
       "2                         0                     0                  0   \n",
       "\n",
       "   Past Information  Future Information Price Sentiment  \\\n",
       "0                 1                   0        negative   \n",
       "1                 1                   0        negative   \n",
       "2                 1                   0        positive   \n",
       "\n",
       "                   News_Chinese  \n",
       "0  四月黄金期货下跌20美分，收于每盎司1116.10美元。  \n",
       "1                   黄金遭遇连续第三天下跌  \n",
       "2                黄金期货在两日下跌后小幅上涨  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import bilbystats as bs\n",
    "\n",
    "# Load in the dataset (originally from https://www.kaggle.com/datasets/ankurzing/sentiment-analysis-in-commodity-market-gold)\n",
    "df = bs.read_data('gold-dataset-sinha-khandait.parquet')\n",
    "\n",
    "# Restrict to the first 1000 rows for this simple example\n",
    "df_first_1000 = df.head(1000)\n",
    "\n",
    "# Illustrate the first 3 rows of the dataframe\n",
    "df_first_1000.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02fd792b",
   "metadata": {},
   "source": [
    "## Performing classification using transformer based models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d81a1e4",
   "metadata": {},
   "source": [
    "### Quickly training transformer classifier based on a same subset of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a897e5e1",
   "metadata": {},
   "source": [
    "We now generate an example of training a classification model on this dataset using bilbystats. We start off using a simple subset of the data so that you can see and example that runs really fast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891f00e0-2a57-44d9-84ae-31e9b0e9064e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 800/800 [00:00<00:00, 17646.39 examples/s]\n",
      "Map: 100%|██████████| 100/100 [00:00<00:00, 16989.93 examples/s]\n",
      "Map: 100%|██████████| 100/100 [00:00<00:00, 16428.28 examples/s]\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "/opt/homebrew/lib/python3.13/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='400' max='400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [400/400 02:42, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.362264</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.901654</td>\n",
       "      <td>0.879340</td>\n",
       "      <td>0.888592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.317178</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.888795</td>\n",
       "      <td>0.897569</td>\n",
       "      <td>0.892750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.338700</td>\n",
       "      <td>0.362722</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.888795</td>\n",
       "      <td>0.897569</td>\n",
       "      <td>0.892750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.338700</td>\n",
       "      <td>0.423557</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.877015</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>0.883856</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.13/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/opt/homebrew/lib/python3.13/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/opt/homebrew/lib/python3.13/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "# Specify the covariate and target columns\n",
    "covariate = 'News'\n",
    "target = 'Price Direction Up'\n",
    "\n",
    "# Split the indices into training, validation, and testing\n",
    "indices = bs.data_idx_split(df_first_1000.index)\n",
    "\n",
    "# Split the data itself into training, validation, and testing sets\n",
    "train_data, valid_data, test_data = bs.train_val_test_split(\n",
    "    df_first_1000, covariate, target, indices)\n",
    "\n",
    "# Define the model name and tokenize the data\n",
    "model_name = \"distilbert-base-uncased\" \n",
    "train_data_tk, valid_data_tk, test_data_tk = bs.tokenize_data(\n",
    "    train_data, valid_data, test_data, model_name)\n",
    "\n",
    "# The following line can be replaced with a str containing your desired directory. \n",
    "savedir = bs.check_dir(\"bs_examples/\") # You can replace this with a str containing your desired directory\n",
    "savename = \"bs_training_example\"\n",
    "\n",
    "# Define the label mapping for the target variable\n",
    "label2id = {\"NEUTRAL\": 0, \"UP\": 1}\n",
    "\n",
    "# Train the model using bilbystats\n",
    "trainer, model, training_args = bs.trainTFmodel(\n",
    "    train_data_tk, valid_data_tk, model_name, savename=savename, savedir=savedir, num_labels=2, label2id=label2id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1bcfd7",
   "metadata": {},
   "source": [
    "Note that due to the small number of datapoints here the training loss is not defined for the first two epochs. In practice I recommend using a greater amount of data in which case that will not be a problem (as e.g. shown below in the example below in which the full dataset is used). This example is designed to run quickly for illustration purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364f3000",
   "metadata": {},
   "source": [
    "We can do the same for the Chinese sentences by simply changing the model as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3c25e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 800/800 [00:00<00:00, 12261.49 examples/s]\n",
      "Map: 100%|██████████| 100/100 [00:00<00:00, 9043.35 examples/s]\n",
      "Map: 100%|██████████| 100/100 [00:00<00:00, 11184.51 examples/s]\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at hfl/chinese-roberta-wwm-ext and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "/opt/homebrew/lib/python3.13/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [300/300 03:56, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.220730</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.908046</td>\n",
       "      <td>0.931424</td>\n",
       "      <td>0.915931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.229893</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.939024</td>\n",
       "      <td>0.960938</td>\n",
       "      <td>0.947207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.232800</td>\n",
       "      <td>0.289713</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.939024</td>\n",
       "      <td>0.960938</td>\n",
       "      <td>0.947207</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.13/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/opt/homebrew/lib/python3.13/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "# Specify the covariate and target columns\n",
    "covariate = 'News_Chinese'\n",
    "target = 'Price Direction Up'\n",
    "\n",
    "# Split the indices into training, validation, and testing\n",
    "indices = bs.data_idx_split(df_first_1000.index)\n",
    "\n",
    "# Split the data itself into training, validation, and testing sets\n",
    "train_data, valid_data, test_data = bs.train_val_test_split(\n",
    "    df_first_1000, covariate, target, indices)\n",
    "\n",
    "# Define the model name and tokenize the data\n",
    "model_name = \"hfl/chinese-roberta-wwm-ext\" \n",
    "train_data_tk, valid_data_tk, test_data_tk = bs.tokenize_data(\n",
    "    train_data, valid_data, test_data, model_name)\n",
    "\n",
    "# Define the output directory and save name for the model\n",
    "savedir = bs.check_dir(\"bs_examples/\") # You can replace this with a str containing your desired directory\n",
    "savename = \"bs_training_example_chinese\"\n",
    "\n",
    "# Define the label mapping for the target variable\n",
    "label2id = {\"NEUTRAL\": 0, \"UP\": 1}\n",
    "\n",
    "# Train the model using bilbystats\n",
    "trainer, model, training_args = bs.trainTFmodel(\n",
    "    train_data_tk, valid_data_tk, model_name, savename=savename, savedir=savedir, num_labels=2, label2id=label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e850052f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 800/800 [00:00<00:00, 11457.85 examples/s]\n",
      "Map: 100%|██████████| 100/100 [00:00<00:00, 12196.29 examples/s]\n",
      "Map: 100%|██████████| 100/100 [00:00<00:00, 12746.71 examples/s]\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at schen/longformer-chinese-base-4096 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "/opt/homebrew/lib/python3.13/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [300/300 04:10, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.376419</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.868506</td>\n",
       "      <td>0.894097</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.326329</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.929688</td>\n",
       "      <td>0.906629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.314100</td>\n",
       "      <td>0.326802</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.916667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.13/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/opt/homebrew/lib/python3.13/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "# Specify the covariate and target columns\n",
    "covariate = 'News_Chinese'\n",
    "target = 'Price Direction Up'\n",
    "\n",
    "# Split the indices into training, validation, and testing\n",
    "indices = bs.data_idx_split(df_first_1000.index)\n",
    "\n",
    "# Split the data itself into training, validation, and testing sets\n",
    "train_data, valid_data, test_data = bs.train_val_test_split(\n",
    "    df_first_1000, covariate, target, indices)\n",
    "\n",
    "# Define the model name and tokenize the data\n",
    "model_name = \"schen/longformer-chinese-base-4096\"\n",
    "train_data_tk, valid_data_tk, test_data_tk = bs.tokenize_data(\n",
    "    train_data, valid_data, test_data, model_name)\n",
    "\n",
    "# Define the output directory and save name for the model\n",
    "savedir = bs.check_dir(\"bs_examples/\") # You can replace this with a str containing your desired directory\n",
    "savename = \"bs_training_example_longformer_chinese\"\n",
    "\n",
    "# Define the label mapping for the target variable\n",
    "label2id = {\"NEUTRAL\": 0, \"UP\": 1}\n",
    "\n",
    "# Train the model using bilbystats\n",
    "trainer, model, training_args = bs.trainTFmodel(\n",
    "    train_data_tk, valid_data_tk, model_name, savename=savename, savedir=savedir, num_labels=2, label2id=label2id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e074c5",
   "metadata": {},
   "source": [
    "### Training on the Full Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0937f4",
   "metadata": {},
   "source": [
    "Below we do the same thing but using a model fit on the whole dataset (maintaining the same split ratios). Note the increase in the metrics.\n",
    "In this case there is no problem with the training loss not being defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf72486-050b-4d82-a526-1b81e7b40b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 8456/8456 [00:00<00:00, 19346.44 examples/s]\n",
      "Map: 100%|██████████| 1057/1057 [00:00<00:00, 19857.92 examples/s]\n",
      "Map: 100%|██████████| 1057/1057 [00:00<00:00, 19154.47 examples/s]\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3171' max='3171' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3171/3171 24:22, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.222800</td>\n",
       "      <td>0.202126</td>\n",
       "      <td>0.947020</td>\n",
       "      <td>0.946968</td>\n",
       "      <td>0.942595</td>\n",
       "      <td>0.944644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.131200</td>\n",
       "      <td>0.242618</td>\n",
       "      <td>0.945128</td>\n",
       "      <td>0.942939</td>\n",
       "      <td>0.942939</td>\n",
       "      <td>0.942939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.085100</td>\n",
       "      <td>0.249069</td>\n",
       "      <td>0.951750</td>\n",
       "      <td>0.950993</td>\n",
       "      <td>0.948477</td>\n",
       "      <td>0.949688</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.13/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/opt/homebrew/lib/python3.13/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "# Specify the covariate and target columns\n",
    "covariate = 'News'\n",
    "target = 'Price Direction Up'\n",
    "\n",
    "# Split the indices into training, validation, and testing\n",
    "indices = bs.data_idx_split(df.index)\n",
    "\n",
    "# Split the data itself into training, validation, and testing sets\n",
    "train_data, valid_data, test_data = bs.train_val_test_split(\n",
    "    df, covariate, target, indices)\n",
    "\n",
    "# Define the model name and tokenize the data\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "train_data_tk, valid_data_tk, test_data_tk = bs.tokenize_data(\n",
    "    train_data, valid_data, test_data, model_name)\n",
    "\n",
    "# Define the output directory and save name for the model\n",
    "savedir = bs.check_dir(\"bs_examples/\") # You can replace this with a str containing your desired directory\n",
    "savename = \"bs_training_example_full\"\n",
    "\n",
    "# Define the label mapping for the target variable\n",
    "label2id = {\"NEUTRAL\": 0, \"UP\": 1}\n",
    "\n",
    "# Train the model using bilbystats\n",
    "trainer, model, training_args = bs.trainTFmodel(\n",
    "    train_data_tk, valid_data_tk, model_name, savename=savename, savedir=savedir, num_labels=2, label2id=label2id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f509931a",
   "metadata": {},
   "source": [
    "We can once more do the same for the Chinese sentences as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90951adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 8456/8456 [00:00<00:00, 14119.53 examples/s]\n",
      "Map: 100%|██████████| 1057/1057 [00:00<00:00, 14232.68 examples/s]\n",
      "Map: 100%|██████████| 1057/1057 [00:00<00:00, 14423.31 examples/s]\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at hfl/chinese-roberta-wwm-ext and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "/opt/homebrew/lib/python3.13/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3171' max='3171' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3171/3171 36:09, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.265300</td>\n",
       "      <td>0.211437</td>\n",
       "      <td>0.940397</td>\n",
       "      <td>0.938789</td>\n",
       "      <td>0.937057</td>\n",
       "      <td>0.937899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.174500</td>\n",
       "      <td>0.196335</td>\n",
       "      <td>0.947966</td>\n",
       "      <td>0.947769</td>\n",
       "      <td>0.943771</td>\n",
       "      <td>0.945654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.113500</td>\n",
       "      <td>0.215896</td>\n",
       "      <td>0.951750</td>\n",
       "      <td>0.951740</td>\n",
       "      <td>0.947707</td>\n",
       "      <td>0.949607</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /Users/samd/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--accuracy/f887c0aab52c2d38e1f8a215681126379eca617f96c447638f751434e8e65b14 (last modified on Fri May  9 20:17:05 2025) since it couldn't be found locally at evaluate-metric--accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /Users/samd/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--precision/155d3220d6cd4a6553f12da68eeb3d1f97cf431206304a4bc6e2d564c29502e9 (last modified on Fri May  9 20:17:06 2025) since it couldn't be found locally at evaluate-metric--precision, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /Users/samd/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--recall/11f90e583db35601050aed380d48e83202a896976b9608432fba9244fb447f24 (last modified on Fri May  9 20:17:08 2025) since it couldn't be found locally at evaluate-metric--recall, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /Users/samd/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--f1/34c46321f42186df33a6260966e34a368f14868d9cc2ba47d142112e2800d233 (last modified on Fri May  9 20:17:09 2025) since it couldn't be found locally at evaluate-metric--f1, or remotely on the Hugging Face Hub.\n",
      "/opt/homebrew/lib/python3.13/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/opt/homebrew/lib/python3.13/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "# Specify the covariate and target columns\n",
    "covariate = 'News_Chinese'\n",
    "target = 'Price Direction Up'\n",
    "\n",
    "# Split the indices into training, validation, and testing\n",
    "indices = bs.data_idx_split(df.index)\n",
    "\n",
    "# Split the data itself into training, validation, and testing sets\n",
    "train_data, valid_data, test_data = bs.train_val_test_split(\n",
    "    df, covariate, target, indices)\n",
    "\n",
    "# Define the model name and tokenize the data\n",
    "model_name = \"hfl/chinese-roberta-wwm-ext\"\n",
    "train_data_tk, valid_data_tk, test_data_tk = bs.tokenize_data(\n",
    "    train_data, valid_data, test_data, model_name)\n",
    "\n",
    "# Define the output directory and save name for the model\n",
    "savedir = bs.check_dir(\"bs_examples/\") # You can replace this with a str containing your desired directory\n",
    "savename = \"bs_training_example_full_chinese\"\n",
    "\n",
    "# Define the label mapping for the target variable\n",
    "label2id = {\"NEUTRAL\": 0, \"UP\": 1}\n",
    "\n",
    "# Train the model using bilbystats\n",
    "trainer, model, training_args = bs.trainTFmodel(\n",
    "    train_data_tk, valid_data_tk, model_name, savename=savename, savedir=savedir, num_labels=2, label2id=label2id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3058b64c",
   "metadata": {},
   "source": [
    "## Performing prediction using the trained models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0302b55",
   "metadata": {},
   "source": [
    "### Prediction using on the English headlines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf95743",
   "metadata": {},
   "source": [
    "We can use the saved models to predict bulk predict the test texts as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3d27647",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1057/1057 [00:00<00:00, 17376.60 examples/s]\n",
      "/opt/homebrew/lib/python3.13/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.9441816461684012"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "model_path = bs.check_dir(\"bs_examples/bs_training_example_full/checkpoint-1057/\")\n",
    "\n",
    "covariate = 'News'\n",
    "target = 'Price Direction Up'\n",
    "\n",
    "# Split the data (using the same seed as before) - this bit is not necessary if you have already peformed the runs above\n",
    "indices = bs.data_idx_split(df.index)\n",
    "train_data, valid_data, test_data = bs.train_val_test_split(df, covariate, target, indices)\n",
    "model_name = \"distilbert-base-uncased\" \n",
    "\n",
    "test_predictions = bs.predict(test_data, model_path, model_name)\n",
    "accuracy_score(test_predictions['true_labels'], test_predictions['pred_labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3830b561",
   "metadata": {},
   "source": [
    "To predict individual pieces of text you can also do the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6f218220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gold edges higher, trades at $1,431.20 an ounce\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 485.90 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Up\n"
     ]
    }
   ],
   "source": [
    "direction_mapping = {\n",
    "    0: 'Neutral',\n",
    "    1: 'Up'\n",
    "}\n",
    "\n",
    "example_sentence = df.loc[indices['test'][0], 'News']\n",
    "print(example_sentence)\n",
    "\n",
    "# You can predict this sentence directly\n",
    "prediction = bs.predict(example_sentence, model_path, model_name)\n",
    "print(direction_mapping[prediction['pred_labels'][0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0a3f5f",
   "metadata": {},
   "source": [
    "This is equivalent to evaluating on the test predictions as we see here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "30b228fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Up\n"
     ]
    }
   ],
   "source": [
    "# Or obtain it from the trained test set\n",
    "prediction2 = test_predictions['pred_labels'][0]\n",
    "print(direction_mapping[prediction2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466102e9",
   "metadata": {},
   "source": [
    "Note that running in bulk rather than individually can save time. But at evaluation time you may at times want to run on individual pieces of text so it's useful to have both types of functionality!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e97db0",
   "metadata": {},
   "source": [
    "### Prediction on the Chinese Headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "327f8d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1057/1057 [00:00<00:00, 13605.17 examples/s]\n",
      "/opt/homebrew/lib/python3.13/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.935666982024598"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "model_path = bs.check_dir(\"bs_examples/bs_training_example_full_chinese/checkpoint-2114/\")\n",
    "\n",
    "covariate = 'News_Chinese'\n",
    "target = 'Price Direction Up'\n",
    "\n",
    "# Split the data (using the same seed as before) - this bit is not necessary if you have already peformed the runs above\n",
    "indices = bs.data_idx_split(df.index)\n",
    "train_data, valid_data, test_data = bs.train_val_test_split(df, covariate, target, indices)\n",
    "model_name = \"hfl/chinese-roberta-wwm-ext\"\n",
    "\n",
    "test_predictions = bs.predict(test_data, model_path, model_name)\n",
    "accuracy_score(test_predictions['true_labels'], test_predictions['pred_labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b08ed3",
   "metadata": {},
   "source": [
    "Note the small loss in test accuracy - this may be due to a translation quality in this case since I've translated the original English headlines to Chinese for this tutorial. In our datasets the original data will be in Chinese so we shouldn't suffer from this effect. \n",
    "\n",
    "As above we can predict pieces of text as follows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca567a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "黄金小幅走高，报每盎司1,431.20美元。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 399.65 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Up\n"
     ]
    }
   ],
   "source": [
    "direction_mapping = {\n",
    "    0: 'Neutral',\n",
    "    1: 'Up'\n",
    "}\n",
    "\n",
    "example_sentence = df.loc[indices['test'][0], 'News_Chinese']\n",
    "print(example_sentence)\n",
    "\n",
    "# You can predict this sentence directly\n",
    "prediction = bs.predict(example_sentence, model_path, model_name)\n",
    "print(direction_mapping[prediction['pred_labels'][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8ad8c4cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Up\n"
     ]
    }
   ],
   "source": [
    "# Or obtain it from the trained test set\n",
    "prediction2 = test_predictions['pred_labels'][0]\n",
    "print(direction_mapping[prediction2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c084c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 526.00 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Up\n"
     ]
    }
   ],
   "source": [
    "# We can also try with examples which are not in the training set. For instance:\n",
    "ex_sentence = bs.translate('Gold is going up', 'gpt-4o', 'Chinese')\n",
    "prediction = bs.predict(ex_sentence, model_path, model_name)\n",
    "print(direction_mapping[prediction['pred_labels'][0]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
