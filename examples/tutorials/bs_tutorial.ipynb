{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "tutorial-title",
   "metadata": {},
   "source": [
    "# Classification Tutorial with BilbyStats\n",
    "\n",
    "This comprehensive tutorial demonstrates how to perform text classification using the BilbyStats library. We'll cover traditional machine learning approaches, transformer-based models, and LLM-based classification.\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Setup and Data Loading](#setup)\n",
    "2. [Data Preparation](#data-prep)\n",
    "3. [Traditional ML Classification](#traditional-ml)\n",
    "4. [Transformer-Based Classification](#transformer)\n",
    "5. [LLM-Based Classification](#llm)\n",
    "6. [Model Evaluation and Comparison](#evaluation)\n",
    "7. [Advanced Topics](#advanced)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-section",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Loading {#setup}\n",
    "\n",
    "First, let's import the necessary libraries and load our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "setup-imports",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (10570, 10)\n",
      "Columns: ['Dates', 'URL', 'News', 'Price Direction Up', 'Price Direction Constant', 'Price Direction Down', 'Asset Comparision', 'Past Information', 'Future Information', 'Price Sentiment']\n",
      "\n",
      "First few rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dates</th>\n",
       "      <th>URL</th>\n",
       "      <th>News</th>\n",
       "      <th>Price Direction Up</th>\n",
       "      <th>Price Direction Constant</th>\n",
       "      <th>Price Direction Down</th>\n",
       "      <th>Asset Comparision</th>\n",
       "      <th>Past Information</th>\n",
       "      <th>Future Information</th>\n",
       "      <th>Price Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28-01-2016</td>\n",
       "      <td>http://www.marketwatch.com/story/april-gold-do...</td>\n",
       "      <td>april gold down 20 cents to settle at $1,116.1...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13-09-2017</td>\n",
       "      <td>http://www.marketwatch.com/story/gold-prices-s...</td>\n",
       "      <td>gold suffers third straight daily decline</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26-07-2016</td>\n",
       "      <td>http://www.marketwatch.com/story/gold-futures-...</td>\n",
       "      <td>Gold futures edge up after two-session decline</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28-02-2018</td>\n",
       "      <td>https://www.metalsdaily.com/link/277199/dent-r...</td>\n",
       "      <td>dent research : is gold's day in the sun comin...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>06-09-2017</td>\n",
       "      <td>http://www.marketwatch.com/story/gold-steadies...</td>\n",
       "      <td>Gold snaps three-day rally as Trump, lawmakers...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Dates                                                URL  \\\n",
       "0  28-01-2016  http://www.marketwatch.com/story/april-gold-do...   \n",
       "1  13-09-2017  http://www.marketwatch.com/story/gold-prices-s...   \n",
       "2  26-07-2016  http://www.marketwatch.com/story/gold-futures-...   \n",
       "3  28-02-2018  https://www.metalsdaily.com/link/277199/dent-r...   \n",
       "4  06-09-2017  http://www.marketwatch.com/story/gold-steadies...   \n",
       "\n",
       "                                                News  Price Direction Up  \\\n",
       "0  april gold down 20 cents to settle at $1,116.1...                   0   \n",
       "1          gold suffers third straight daily decline                   0   \n",
       "2     Gold futures edge up after two-session decline                   1   \n",
       "3  dent research : is gold's day in the sun comin...                   0   \n",
       "4  Gold snaps three-day rally as Trump, lawmakers...                   0   \n",
       "\n",
       "   Price Direction Constant  Price Direction Down  Asset Comparision  \\\n",
       "0                         0                     1                  0   \n",
       "1                         0                     1                  0   \n",
       "2                         0                     0                  0   \n",
       "3                         0                     0                  0   \n",
       "4                         0                     1                  0   \n",
       "\n",
       "   Past Information  Future Information Price Sentiment  \n",
       "0                 1                   0        negative  \n",
       "1                 1                   0        negative  \n",
       "2                 1                   0        positive  \n",
       "3                 0                   1            none  \n",
       "4                 1                   0        negative  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import bilbystats as bs\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load the gold dataset for financial sentiment analysis\n",
    "df = bs.read_data('gold-dataset-sinha-khandait.csv')\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "data-exploration",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target variable distribution:\n",
      "Price Direction Up\n",
      "0    6158\n",
      "1    4412\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample news text:\n",
      "Text 1: april gold down 20 cents to settle at $1,116.10/oz\n",
      "Label: 0\n",
      "\n",
      "Text 2: gold suffers third straight daily decline\n",
      "Label: 0\n",
      "\n",
      "Text 3: Gold futures edge up after two-session decline\n",
      "Label: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Examine the distribution of our target variable\n",
    "print(\"Target variable distribution:\")\n",
    "print(df['Price Direction Up'].value_counts())\n",
    "\n",
    "# Look at some example texts\n",
    "print(\"\\nSample news text:\")\n",
    "for i in range(3):\n",
    "    print(f\"Text {i+1}: {df['News'].iloc[i]}\")\n",
    "    print(f\"Label: {df['Price Direction Up'].iloc[i]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-prep-section",
   "metadata": {},
   "source": [
    "## 2. Data Preparation {#data-prep}\n",
    "\n",
    "BilbyStats provides convenient functions for splitting data and preparing it for different types of models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "data-preparation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 1400\n",
      "Validation samples: 300\n",
      "Test samples: 300\n",
      "\n",
      "Training data shape: 1400\n",
      "Validation data shape: 300\n",
      "Test data shape: 300\n"
     ]
    }
   ],
   "source": [
    "# For this tutorial, let's use a subset for faster training\n",
    "df_subset = df.head(2000)  # Adjust size based on your computational resources\n",
    "\n",
    "# Define our input text column and target variable\n",
    "covariate = 'News'\n",
    "target = 'Price Direction Up'\n",
    "\n",
    "# Split indices into train/validation/test sets\n",
    "indices = bs.data_idx_split(df_subset.index, ratio=0.3, valratio=0.5, random_state=42)\n",
    "\n",
    "print(f\"Training samples: {len(indices['train'])}\")\n",
    "print(f\"Validation samples: {len(indices['valid'])}\")\n",
    "print(f\"Test samples: {len(indices['test'])}\")\n",
    "\n",
    "# Create train/validation/test datasets for transformer models\n",
    "train_data, valid_data, test_data = bs.train_val_test_split(\n",
    "    df_subset, covariate, target, indices\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining data shape: {len(train_data)}\")\n",
    "print(f\"Validation data shape: {len(valid_data)}\")\n",
    "print(f\"Test data shape: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "traditional-ml-section",
   "metadata": {},
   "source": [
    "## 3. Traditional ML Classification {#traditional-ml}\n",
    "\n",
    "Before jumping to deep learning, let's establish a baseline using traditional machine learning approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "traditional-ml",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.7967\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.92      0.83       166\n",
      "           1       0.87      0.64      0.74       134\n",
      "\n",
      "    accuracy                           0.80       300\n",
      "   macro avg       0.81      0.78      0.79       300\n",
      "weighted avg       0.81      0.80      0.79       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Create TF-IDF features\n",
    "vectorizer = TfidfVectorizer(max_features=5000, stop_words='english')\n",
    "\n",
    "# Extract texts and labels\n",
    "train_texts = [train_data[i]['text'] for i in range(len(train_data))]\n",
    "train_labels = [train_data[i]['label'] for i in range(len(train_data))]\n",
    "\n",
    "valid_texts = [valid_data[i]['text'] for i in range(len(valid_data))]\n",
    "valid_labels = [valid_data[i]['label'] for i in range(len(valid_data))]\n",
    "\n",
    "test_texts = [test_data[i]['text'] for i in range(len(test_data))]\n",
    "test_labels = [test_data[i]['label'] for i in range(len(test_data))]\n",
    "\n",
    "# Fit vectorizer and transform texts\n",
    "X_train = vectorizer.fit_transform(train_texts)\n",
    "X_valid = vectorizer.transform(valid_texts)\n",
    "X_test = vectorizer.transform(test_texts)\n",
    "\n",
    "# Train logistic regression model\n",
    "lr_model = LogisticRegression(random_state=42)\n",
    "lr_model.fit(X_train, train_labels)\n",
    "\n",
    "# Make predictions\n",
    "lr_predictions = lr_model.predict(X_test)\n",
    "lr_accuracy = accuracy_score(test_labels, lr_predictions)\n",
    "\n",
    "print(f\"Logistic Regression Accuracy: {lr_accuracy:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(test_labels, lr_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "transformer-section",
   "metadata": {},
   "source": [
    "## 4. Transformer-Based Classification {#transformer}\n",
    "\n",
    "Now let's use BilbyStats to train a transformer-based model for better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "tokenization",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1400/1400 [00:00<00:00, 18365.69 examples/s]\n",
      "Map: 100%|██████████| 300/300 [00:00<00:00, 19839.67 examples/s]\n",
      "Map: 100%|██████████| 300/300 [00:00<00:00, 19407.29 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data tokenized successfully!\n",
      "Training tokens shape: torch.Size([1400, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Choose a pre-trained model\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "\n",
    "# Tokenize the datasets for transformer training\n",
    "train_data_tk, valid_data_tk, test_data_tk = bs.tokenize_data(\n",
    "    train_data, valid_data, test_data, model_name\n",
    ")\n",
    "\n",
    "print(\"Data tokenized successfully!\")\n",
    "print(f\"Training tokens shape: {train_data_tk['input_ids'].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "transformer-training",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 03:14, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.308849</td>\n",
       "      <td>0.886667</td>\n",
       "      <td>0.892978</td>\n",
       "      <td>0.881152</td>\n",
       "      <td>0.884401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.397800</td>\n",
       "      <td>0.327547</td>\n",
       "      <td>0.906667</td>\n",
       "      <td>0.908609</td>\n",
       "      <td>0.903632</td>\n",
       "      <td>0.905452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.397800</td>\n",
       "      <td>0.367787</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.916787</td>\n",
       "      <td>0.915163</td>\n",
       "      <td>0.915881</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 200.006812 seconds\n",
      "Training completed!\n"
     ]
    }
   ],
   "source": [
    "# Set up training configuration\n",
    "savedir = \"./model_checkpoints/\"  # Change this to your desired directory\n",
    "savename = \"financial_sentiment_classifier\"\n",
    "\n",
    "# Define label mapping\n",
    "label2id = {\"NEGATIVE\": 0, \"POSITIVE\": 1}\n",
    "num_labels = len(label2id)\n",
    "\n",
    "# Train the transformer model\n",
    "print(\"Starting training...\")\n",
    "bs.tic()  # Start timer\n",
    "\n",
    "trainer, model, training_args = bs.trainTFmodel(\n",
    "    train_data_tk, \n",
    "    valid_data_tk, \n",
    "    model_name, \n",
    "    savename=savename, \n",
    "    savedir=savedir, \n",
    "    num_labels=num_labels, \n",
    "    label2id=label2id\n",
    ")\n",
    "\n",
    "bs.toc()  # End timer\n",
    "print(\"Training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "transformer-evaluation",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 300/300 [00:00<00:00, 13633.95 examples/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unrecognized model in ./model_checkpoints/financial_sentiment_classifier. Should have a `model_type` key in its config.json, or contain one of the following strings in its name: albert, align, altclip, aria, aria_text, audio-spectrogram-transformer, autoformer, aya_vision, bamba, bark, bart, beit, bert, bert-generation, big_bird, bigbird_pegasus, biogpt, bit, blenderbot, blenderbot-small, blip, blip-2, bloom, bridgetower, bros, camembert, canine, chameleon, chinese_clip, chinese_clip_vision_model, clap, clip, clip_text_model, clip_vision_model, clipseg, clvp, code_llama, codegen, cohere, cohere2, colpali, conditional_detr, convbert, convnext, convnextv2, cpmant, ctrl, cvt, dab-detr, dac, data2vec-audio, data2vec-text, data2vec-vision, dbrx, deberta, deberta-v2, decision_transformer, deepseek_v3, deformable_detr, deit, depth_anything, depth_pro, deta, detr, diffllama, dinat, dinov2, dinov2_with_registers, distilbert, donut-swin, dpr, dpt, efficientformer, efficientnet, electra, emu3, encodec, encoder-decoder, ernie, ernie_m, esm, falcon, falcon_mamba, fastspeech2_conformer, flaubert, flava, fnet, focalnet, fsmt, funnel, fuyu, gemma, gemma2, gemma3, gemma3_text, git, glm, glm4, glpn, got_ocr2, gpt-sw3, gpt2, gpt_bigcode, gpt_neo, gpt_neox, gpt_neox_japanese, gptj, gptsan-japanese, granite, granitemoe, granitemoeshared, granitevision, graphormer, grounding-dino, groupvit, helium, hiera, hubert, ibert, idefics, idefics2, idefics3, idefics3_vision, ijepa, imagegpt, informer, instructblip, instructblipvideo, jamba, jetmoe, jukebox, kosmos-2, layoutlm, layoutlmv2, layoutlmv3, led, levit, lilt, llama, llama4, llama4_text, llava, llava_next, llava_next_video, llava_onevision, longformer, longt5, luke, lxmert, m2m_100, mamba, mamba2, marian, markuplm, mask2former, maskformer, maskformer-swin, mbart, mctct, mega, megatron-bert, mgp-str, mimi, mistral, mistral3, mixtral, mllama, mobilebert, mobilenet_v1, mobilenet_v2, mobilevit, mobilevitv2, modernbert, moonshine, moshi, mpnet, mpt, mra, mt5, musicgen, musicgen_melody, mvp, nat, nemotron, nezha, nllb-moe, nougat, nystromformer, olmo, olmo2, olmoe, omdet-turbo, oneformer, open-llama, openai-gpt, opt, owlv2, owlvit, paligemma, patchtsmixer, patchtst, pegasus, pegasus_x, perceiver, persimmon, phi, phi3, phi4_multimodal, phimoe, pix2struct, pixtral, plbart, poolformer, pop2piano, prompt_depth_anything, prophetnet, pvt, pvt_v2, qdqbert, qwen2, qwen2_5_vl, qwen2_audio, qwen2_audio_encoder, qwen2_moe, qwen2_vl, qwen3, qwen3_moe, rag, realm, recurrent_gemma, reformer, regnet, rembert, resnet, retribert, roberta, roberta-prelayernorm, roc_bert, roformer, rt_detr, rt_detr_resnet, rt_detr_v2, rwkv, sam, sam_vision_model, seamless_m4t, seamless_m4t_v2, segformer, seggpt, sew, sew-d, shieldgemma2, siglip, siglip2, siglip_vision_model, smolvlm, smolvlm_vision, speech-encoder-decoder, speech_to_text, speech_to_text_2, speecht5, splinter, squeezebert, stablelm, starcoder2, superglue, superpoint, swiftformer, swin, swin2sr, swinv2, switch_transformers, t5, table-transformer, tapas, textnet, time_series_transformer, timesformer, timm_backbone, timm_wrapper, trajectory_transformer, transfo-xl, trocr, tvlt, tvp, udop, umt5, unispeech, unispeech-sat, univnet, upernet, van, video_llava, videomae, vilt, vipllava, vision-encoder-decoder, vision-text-dual-encoder, visual_bert, vit, vit_hybrid, vit_mae, vit_msn, vitdet, vitmatte, vitpose, vitpose_backbone, vits, vivit, wav2vec2, wav2vec2-bert, wav2vec2-conformer, wavlm, whisper, xclip, xglm, xlm, xlm-prophetnet, xlm-roberta, xlm-roberta-xl, xlnet, xmod, yolos, yoso, zamba, zamba2, zoedepth",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msavedir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msavename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Make predictions on test set\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mbs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m transformer_accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(predictions[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrue_labels\u001b[39m\u001b[38;5;124m'\u001b[39m], predictions[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpred_labels\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTransformer Model Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtransformer_accuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.13/site-packages/bilbystats/transformer_models/inference.py:45\u001b[0m, in \u001b[0;36mpredict\u001b[0;34m(data, model_path, model_name)\u001b[0m\n\u001b[1;32m     42\u001b[0m data2predict_tk \u001b[38;5;241m=\u001b[39m bs\u001b[38;5;241m.\u001b[39mtokenize(data, model_name)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# Load in the model and the trainer\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForSequenceClassification\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# Calculate the model predictions\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.13/site-packages/transformers/models/auto/auto_factory.py:531\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquantization_config\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    529\u001b[0m     _ \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquantization_config\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 531\u001b[0m config, kwargs \u001b[38;5;241m=\u001b[39m \u001b[43mAutoConfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    532\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    533\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_unused_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    534\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    535\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcode_revision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcode_revision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    536\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    537\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    538\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    539\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;66;03m# if torch_dtype=auto was passed here, ensure to pass it on\u001b[39;00m\n\u001b[1;32m    542\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs_orig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch_dtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.13/site-packages/transformers/models/auto/configuration_auto.py:1151\u001b[0m, in \u001b[0;36mAutoConfig.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m   1148\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m pattern \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(pretrained_model_name_or_path):\n\u001b[1;32m   1149\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m CONFIG_MAPPING[pattern]\u001b[38;5;241m.\u001b[39mfrom_dict(config_dict, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munused_kwargs)\n\u001b[0;32m-> 1151\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1152\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized model in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1153\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould have a `model_type` key in its \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mCONFIG_NAME\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, or contain one of the following strings \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1154\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124min its name: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(CONFIG_MAPPING\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1155\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: Unrecognized model in ./model_checkpoints/financial_sentiment_classifier. Should have a `model_type` key in its config.json, or contain one of the following strings in its name: albert, align, altclip, aria, aria_text, audio-spectrogram-transformer, autoformer, aya_vision, bamba, bark, bart, beit, bert, bert-generation, big_bird, bigbird_pegasus, biogpt, bit, blenderbot, blenderbot-small, blip, blip-2, bloom, bridgetower, bros, camembert, canine, chameleon, chinese_clip, chinese_clip_vision_model, clap, clip, clip_text_model, clip_vision_model, clipseg, clvp, code_llama, codegen, cohere, cohere2, colpali, conditional_detr, convbert, convnext, convnextv2, cpmant, ctrl, cvt, dab-detr, dac, data2vec-audio, data2vec-text, data2vec-vision, dbrx, deberta, deberta-v2, decision_transformer, deepseek_v3, deformable_detr, deit, depth_anything, depth_pro, deta, detr, diffllama, dinat, dinov2, dinov2_with_registers, distilbert, donut-swin, dpr, dpt, efficientformer, efficientnet, electra, emu3, encodec, encoder-decoder, ernie, ernie_m, esm, falcon, falcon_mamba, fastspeech2_conformer, flaubert, flava, fnet, focalnet, fsmt, funnel, fuyu, gemma, gemma2, gemma3, gemma3_text, git, glm, glm4, glpn, got_ocr2, gpt-sw3, gpt2, gpt_bigcode, gpt_neo, gpt_neox, gpt_neox_japanese, gptj, gptsan-japanese, granite, granitemoe, granitemoeshared, granitevision, graphormer, grounding-dino, groupvit, helium, hiera, hubert, ibert, idefics, idefics2, idefics3, idefics3_vision, ijepa, imagegpt, informer, instructblip, instructblipvideo, jamba, jetmoe, jukebox, kosmos-2, layoutlm, layoutlmv2, layoutlmv3, led, levit, lilt, llama, llama4, llama4_text, llava, llava_next, llava_next_video, llava_onevision, longformer, longt5, luke, lxmert, m2m_100, mamba, mamba2, marian, markuplm, mask2former, maskformer, maskformer-swin, mbart, mctct, mega, megatron-bert, mgp-str, mimi, mistral, mistral3, mixtral, mllama, mobilebert, mobilenet_v1, mobilenet_v2, mobilevit, mobilevitv2, modernbert, moonshine, moshi, mpnet, mpt, mra, mt5, musicgen, musicgen_melody, mvp, nat, nemotron, nezha, nllb-moe, nougat, nystromformer, olmo, olmo2, olmoe, omdet-turbo, oneformer, open-llama, openai-gpt, opt, owlv2, owlvit, paligemma, patchtsmixer, patchtst, pegasus, pegasus_x, perceiver, persimmon, phi, phi3, phi4_multimodal, phimoe, pix2struct, pixtral, plbart, poolformer, pop2piano, prompt_depth_anything, prophetnet, pvt, pvt_v2, qdqbert, qwen2, qwen2_5_vl, qwen2_audio, qwen2_audio_encoder, qwen2_moe, qwen2_vl, qwen3, qwen3_moe, rag, realm, recurrent_gemma, reformer, regnet, rembert, resnet, retribert, roberta, roberta-prelayernorm, roc_bert, roformer, rt_detr, rt_detr_resnet, rt_detr_v2, rwkv, sam, sam_vision_model, seamless_m4t, seamless_m4t_v2, segformer, seggpt, sew, sew-d, shieldgemma2, siglip, siglip2, siglip_vision_model, smolvlm, smolvlm_vision, speech-encoder-decoder, speech_to_text, speech_to_text_2, speecht5, splinter, squeezebert, stablelm, starcoder2, superglue, superpoint, swiftformer, swin, swin2sr, swinv2, switch_transformers, t5, table-transformer, tapas, textnet, time_series_transformer, timesformer, timm_backbone, timm_wrapper, trajectory_transformer, transfo-xl, trocr, tvlt, tvp, udop, umt5, unispeech, unispeech-sat, univnet, upernet, van, video_llava, videomae, vilt, vipllava, vision-encoder-decoder, vision-text-dual-encoder, visual_bert, vit, vit_hybrid, vit_mae, vit_msn, vitdet, vitmatte, vitpose, vitpose_backbone, vits, vivit, wav2vec2, wav2vec2-bert, wav2vec2-conformer, wavlm, whisper, xclip, xglm, xlm, xlm-prophetnet, xlm-roberta, xlm-roberta-xl, xlnet, xmod, yolos, yoso, zamba, zamba2, zoedepth"
     ]
    }
   ],
   "source": [
    "# Evaluate the transformer model\n",
    "model_path = f\"{savedir}{savename}\"\n",
    "\n",
    "# Make predictions on test set\n",
    "predictions = bs.predict(test_data, model_path, model_name)\n",
    "\n",
    "transformer_accuracy = accuracy_score(predictions['true_labels'], predictions['pred_labels'])\n",
    "print(f\"Transformer Model Accuracy: {transformer_accuracy:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(predictions['true_labels'], predictions['pred_labels']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "llm-section",
   "metadata": {},
   "source": [
    "## 5. LLM-Based Classification {#llm}\n",
    "\n",
    "BilbyStats also supports classification using large language models. Let's try different approaches.\n",
    "\n",
    "### 5.1 Single Sample Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "llm-single-sample",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample text: gold falls as dollar strengthens on retail sales\n",
      "True label: 0\n",
      "gpt-4o-mini prediction: negative\n",
      "claude prediction: negative\n",
      "gemini prediction: negative\n",
      "\n",
      "llama prediction: negative\n"
     ]
    }
   ],
   "source": [
    "# Test single sample classification with different models\n",
    "sample_text = test_texts[0]\n",
    "true_label = test_labels[0]\n",
    "\n",
    "print(f\"Sample text: {sample_text}\")\n",
    "print(f\"True label: {true_label}\")\n",
    "\n",
    "# Try different LLM models (adjust based on your available models)\n",
    "models_to_test = [\"gpt-4o-mini\", \"claude\", \"gemini\", \"llama\"]\n",
    "\n",
    "for model in models_to_test:\n",
    "    try:\n",
    "        sentiment = bs.detect_sentiment(sample_text, model_name=model)\n",
    "        print(f\"{model} prediction: {sentiment}\")\n",
    "    except Exception as e:\n",
    "        print(f\"{model} error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "batch-classification",
   "metadata": {},
   "source": [
    "### 5.2 Batch Classification with Custom Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "load-prompts",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple prompt:\n",
      "You are a sentiment analysis expert for financial text.\n",
      "Classify each input sentence based on sentiment.\n",
      "\n",
      "Return your answer in the following format:\n",
      "Label: <one of [negative, neutral, positive]>\n",
      "\n",
      "Be concise and precise.\n",
      "\n",
      "Detailed prompt:\n",
      "You are a sentiment analysis expert for financial text.\n",
      "Classify each input sentence based on sentiment.\n",
      "\n",
      "Return your answer in the following format:\n",
      "Label: <one of [negative, neutral, positive]>\n",
      "Explanation: <brief explanation (1–2 sentences) of why this label applies>\n",
      "\n",
      "Be concise and precise.\n"
     ]
    }
   ],
   "source": [
    "# Define prompt templates (you can also load these from files if they exist)\n",
    "simple_prompt = \"\"\"You are a sentiment analysis expert for financial text.\n",
    "Classify each input sentence based on sentiment.\n",
    "\n",
    "Return your answer in the following format:\n",
    "Label: <one of [negative, neutral, positive]>\n",
    "\n",
    "Be concise and precise.\"\"\"\n",
    "\n",
    "detailed_prompt = \"\"\"You are a sentiment analysis expert for financial text.\n",
    "Classify each input sentence based on sentiment.\n",
    "\n",
    "Return your answer in the following format:\n",
    "Label: <one of [negative, neutral, positive]>\n",
    "Explanation: <brief explanation (1–2 sentences) of why this label applies>\n",
    "\n",
    "Be concise and precise.\"\"\"\n",
    "\n",
    "print(\"Simple prompt:\")\n",
    "print(simple_prompt)\n",
    "print(\"\\nDetailed prompt:\")\n",
    "print(detailed_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "batch-llm-classification",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM classification error: api2data() got an unexpected keyword argument 'labels'\n",
      "This might be due to model availability or API configuration.\n"
     ]
    }
   ],
   "source": [
    "# Classify a small batch using api2data function\n",
    "# First, create a small test dataset\n",
    "test_sample = df_subset.head(10).copy()\n",
    "\n",
    "# Save to parquet for api2data function\n",
    "test_input_path = \"./test_sample_input.parquet\"\n",
    "test_output_path = \"./test_sample_output.parquet\"\n",
    "test_sample.to_parquet(test_input_path)\n",
    "\n",
    "# Save the prompt to a file\n",
    "prompt_path = \"./sentiment_classification.txt\"\n",
    "with open(prompt_path, 'w') as f:\n",
    "    f.write(simple_prompt)\n",
    "\n",
    "# Run batch classification (adjust model_name based on availability)\n",
    "try:\n",
    "    bs.api2data(\n",
    "        colname='News',\n",
    "        promptloc=prompt_path,\n",
    "        dataloc=test_input_path,\n",
    "        saveloc=test_output_path,\n",
    "        task='Classify the sentiment of the following news text: ',\n",
    "        model_name=\"llama\",  # Change to available model\n",
    "        labels=['Label:'],\n",
    "        names=['sentiment'],\n",
    "        lowercase=[True]\n",
    "    )\n",
    "    \n",
    "    # Load and examine results\n",
    "    llm_results = pd.read_parquet(test_output_path)\n",
    "    print(\"LLM Classification Results:\")\n",
    "    print(llm_results[['News', 'Price Direction Up', 'llama_sentiment']].head())\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"LLM classification error: {e}\")\n",
    "    print(\"This might be due to model availability or API configuration.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "evaluation-section",
   "metadata": {},
   "source": [
    "## 6. Model Evaluation and Comparison {#evaluation}\n",
    "\n",
    "Let's compare the performance of all our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "model-comparison",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a comparison DataFrame\n",
    "results_comparison = pd.DataFrame({\n",
    "    'Model': ['Logistic Regression', 'DistilBERT'],\n",
    "    'Accuracy': [lr_accuracy, transformer_accuracy],\n",
    "    'Type': ['Traditional ML', 'Transformer']\n",
    "})\n",
    "\n",
    "print(\"Model Comparison:\")\n",
    "print(results_comparison)\n",
    "\n",
    "# Plot comparison\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(results_comparison['Model'], results_comparison['Accuracy'])\n",
    "plt.title('Model Performance Comparison')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advanced-evaluation",
   "metadata": {},
   "source": [
    "### 6.1 Advanced Evaluation with BilbyStats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advanced-evaluation-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use BilbyStats' built-in prediction functions for more detailed evaluation\n",
    "try:\n",
    "    df_predictions = bs.predict_df(\n",
    "        df_subset, \n",
    "        covariate, \n",
    "        model_path, \n",
    "        model_name, \n",
    "        indices['test'], \n",
    "        target\n",
    "    )\n",
    "    \n",
    "    # Calculate metrics\n",
    "    test_accuracy = accuracy_score(df_predictions['true_labels'], df_predictions['pred_labels'])\n",
    "    print(f\"Test Accuracy (using predict_df): {test_accuracy:.4f}\")\n",
    "    \n",
    "    # Analyze prediction confidence\n",
    "    logits = df_predictions['logits']\n",
    "    confidence_scores = np.max(logits, axis=1)\n",
    "    print(f\"Average confidence: {np.mean(confidence_scores):.4f}\")\n",
    "    print(f\"Min confidence: {np.min(confidence_scores):.4f}\")\n",
    "    print(f\"Max confidence: {np.max(confidence_scores):.4f}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Advanced evaluation error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advanced-section",
   "metadata": {},
   "source": [
    "## 7. Advanced Topics {#advanced}\n",
    "\n",
    "### 7.1 Text Similarity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "similarity-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare similarity between different texts\n",
    "text1 = \"Gold prices surge amid market uncertainty\"\n",
    "text2 = \"Gold futures rise due to economic concerns\"\n",
    "text3 = \"Stock market crashes heavily today\"\n",
    "\n",
    "# Calculate cosine similarity using different models\n",
    "models = ['distilbert-base-uncased', 'roberta-large']\n",
    "\n",
    "for model in models:\n",
    "    try:\n",
    "        sim_1_2 = bs.cos_sim(text1, text2, model)\n",
    "        sim_1_3 = bs.cos_sim(text1, text3, model)\n",
    "        print(f\"{model}:\")\n",
    "        print(f\"  Gold texts similarity: {sim_1_2:.4f}\")\n",
    "        print(f\"  Gold vs Stock similarity: {sim_1_3:.4f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error with {model}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finbert-section",
   "metadata": {},
   "source": [
    "### 7.2 Sentiment Analysis with FinBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finbert-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use specialized financial sentiment model\n",
    "financial_texts = [\n",
    "    \"Gold prices declined sharply today\",\n",
    "    \"Strong economic indicators boost market confidence\",\n",
    "    \"Uncertainty in global markets affects gold demand\"\n",
    "]\n",
    "\n",
    "for text in financial_texts:\n",
    "    try:\n",
    "        score = bs.get_sentiment_score(text)\n",
    "        print(f\"Text: {text}\")\n",
    "        print(f\"Sentiment Score: {score:.4f}\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error analyzing: {text}, Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "translation-section",
   "metadata": {},
   "source": [
    "### 7.3 Translation and Multilingual Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "translation-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test translation capabilities\n",
    "chinese_text = \"黄金价格今天上涨了\"\n",
    "\n",
    "try:\n",
    "    english_translation = bs.translate(chinese_text, model_name=\"llama\", languageout=\"English\")\n",
    "    \n",
    "    print(f\"Chinese: {chinese_text}\")\n",
    "    print(f\"English: {english_translation}\")\n",
    "    \n",
    "    # Analyze sentiment in both languages\n",
    "    chinese_sentiment = bs.detect_sentiment(chinese_text, model_name=\"llama\")\n",
    "    english_sentiment = bs.detect_sentiment(english_translation, model_name=\"llama\")\n",
    "    \n",
    "    print(f\"Chinese sentiment: {chinese_sentiment}\")\n",
    "    print(f\"English sentiment: {english_sentiment}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Translation error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cost-section",
   "metadata": {},
   "source": [
    "### 7.4 Cost Estimation for LLM Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cost-estimation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate costs for LLM API calls\n",
    "sample_input = \"Gold prices are volatile today\"\n",
    "sample_output = \"negative\"\n",
    "model_name_cost = \"gpt-4o\"\n",
    "\n",
    "try:\n",
    "    costs = bs.model_costs(sample_input, sample_output, model_name_cost, ndocs=1)\n",
    "    print(\"Cost Analysis:\")\n",
    "    print(f\"Input tokens: {costs['n_input_tokens']}\")\n",
    "    print(f\"Output tokens: {costs['m_output_tokens']}\")\n",
    "    print(f\"Total cost: ${costs['total_cost']:.6f}\")\n",
    "except Exception as e:\n",
    "    print(f\"Cost calculation error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-generation",
   "metadata": {},
   "source": [
    "### 7.5 Data Generation and Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "data-generation-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of data generation using BilbyStats\n",
    "# Extract random sentences from text data\n",
    "sample_text = df['News'].iloc[0]\n",
    "print(f\"Original text: {sample_text}\")\n",
    "\n",
    "try:\n",
    "    # Get sentences from text\n",
    "    sentences = bs.get_sentences(sample_text, minlen=10, language='English')\n",
    "    print(f\"\\nExtracted sentences ({len(sentences)}):\")\n",
    "    for i, sentence in enumerate(sentences[:3]):  # Show first 3\n",
    "        print(f\"{i+1}. {sentence}\")\n",
    "    \n",
    "    # Get a random sentence\n",
    "    if sentences:\n",
    "        random_sentence = bs.get_random_sentence(sample_text, minlen=10)\n",
    "        print(f\"\\nRandom sentence: {random_sentence}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Sentence extraction error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "timing-section",
   "metadata": {},
   "source": [
    "### 7.6 Performance Timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "timing-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare inference times for different approaches\n",
    "sample_texts = test_texts[:5]  # Use first 5 test samples\n",
    "\n",
    "# Time traditional ML prediction\n",
    "bs.tic()\n",
    "X_sample = vectorizer.transform(sample_texts)\n",
    "lr_preds = lr_model.predict(X_sample)\n",
    "lr_time = bs.toc()\n",
    "\n",
    "print(f\"Logistic Regression predictions: {lr_preds}\")\n",
    "print(f\"Time taken: {lr_time:.4f} seconds\")\n",
    "\n",
    "# Time transformer prediction (if model is available)\n",
    "try:\n",
    "    bs.tic()\n",
    "    # Create small dataset for transformer\n",
    "    sample_dataset = bs.df2dict(pd.DataFrame({'text': sample_texts}), 'text')\n",
    "    transformer_preds = bs.predict(sample_dataset, model_path, model_name)\n",
    "    transformer_time = bs.toc()\n",
    "    \n",
    "    print(f\"\\nTransformer predictions: {transformer_preds['pred_labels']}\")\n",
    "    print(f\"Time taken: {transformer_time:.4f} seconds\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\nTransformer timing error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary-section",
   "metadata": {},
   "source": [
    "## Summary and Best Practices\n",
    "\n",
    "1. **Start Simple**: Begin with traditional ML models to establish baselines\n",
    "2. **Use Transformers for Better Performance**: DistilBERT and similar models often provide significant improvements\n",
    "3. **Consider LLMs for Complex Tasks**: Use GPT, Claude, or Gemini for tasks requiring reasoning\n",
    "4. **Monitor Costs**: Be aware of API costs when using commercial LLMs\n",
    "5. **Validate Results**: Always use proper train/validation/test splits\n",
    "6. **Choose Appropriate Models**: Consider your specific domain (e.g., FinBERT for financial texts)\n",
    "7. **Time vs Accuracy Trade-offs**: Traditional ML is fastest, transformers balance speed and accuracy, LLMs are most flexible but slowest\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- Experiment with different transformer architectures\n",
    "- Try few-shot learning with LLMs\n",
    "- Implement active learning pipelines\n",
    "- Explore multi-label classification\n",
    "- Consider model ensembling techniques\n",
    "- Use domain-specific models (like FinBERT for financial data)\n",
    "\n",
    "This tutorial provides a comprehensive introduction to classification with BilbyStats. Adapt the code to your specific use case and data!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
